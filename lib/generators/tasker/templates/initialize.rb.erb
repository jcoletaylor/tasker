# frozen_string_literal: true

# Configure Tasker
Tasker.configuration do |config|
  # Engine configuration
  # config.engine do |engine|
  #   engine.task_handler_directory = 'custom_tasks'
  #   engine.task_config_directory = 'custom_tasks'
  #   engine.default_module_namespace = 'OurTasks'
  #   engine.identity_strategy = :hash
  #   engine.identity_strategy_class = 'MyApp::CustomIdentityStrategy'
  # end

  # Authentication and authorization configuration
  # config.auth do |auth|
  #   auth.strategy = :devise
  #   auth.options = { scope: :user }
  #   auth.enabled = true
  #   auth.coordinator_class = 'MyApp::AuthorizationCoordinator'
  #   auth.user_class = 'User'
  # end

  # Database configuration
  # config.database do |db|
  #   db.enable_secondary_database = true
  #   db.name = :tasker
  # end

  # Telemetry and observability configuration
  # Tasker provides two complementary observability systems:
  # 1. TelemetrySubscriber (event-driven OpenTelemetry spans for detailed tracing)
  # 2. MetricsBackend (native metrics collection for dashboards and alerting)
  # config.telemetry do |tel|
  #   # === OPENTELEMETRY SPANS (Event-Driven Tracing) ===
  #   tel.enabled = true                              # Enable TelemetrySubscriber
  #   tel.service_name = 'my_app_tasker'
  #   tel.service_version = '1.2.3'
  #
  #   # === STRUCTURED LOGGING ===
  #   tel.structured_logging_enabled = true
  #   tel.correlation_id_header = 'X-Correlation-ID'  # HTTP header for correlation ID propagation
  #   tel.log_level = 'info'                          # debug, info, warn, error, fatal
  #   tel.log_format = 'json'                         # json, pretty_json, logfmt
  #
  #   # === SENSITIVE DATA FILTERING ===
  #   tel.filter_mask = '***REDACTED***'
  #   tel.filter_parameters = [:password, :api_key, 'credit_card.number', /token/i]
  #
  #   # === NATIVE METRICS COLLECTION (Direct Collection) ===
  #   tel.metrics_enabled = true                      # Enable MetricsBackend
  #   tel.metrics_format = 'prometheus'               # 'prometheus', 'json', 'csv'
  #
  #   # Prometheus export configuration (matches TelemetryConfig.default_prometheus_config)
  #   tel.prometheus = {
  #     endpoint: ENV['PROMETHEUS_ENDPOINT'],         # Prometheus remote write endpoint (nil disables)
  #
  #     # Basic authentication for Prometheus endpoint
  #     username: ENV['PROMETHEUS_USERNAME'],
  #     password: ENV['PROMETHEUS_PASSWORD'],
  #
  #     # Job configuration
  #     job_timeout: 5.minutes,
  #     export_timeout: 2.minutes,
  #     retry_attempts: 3,
  #
  #     # Export scheduling
  #     retention_window: 5.minutes,                 # How long metrics are retained before TTL expiry
  #     safety_margin: 1.minute,                     # Export before TTL expires (safety buffer)
  #
  #     # Metric naming
  #     metric_prefix: 'tasker',
  #     include_instance_labels: true,
  #
  #     # Performance tuning
  #     compression: 'snappy',                       # 'snappy', 'gzip', or nil
  #     batch_size: 1000,
  #
  #     # Test/development mode
  #     skip_if_unavailable: true                    # Don't fail if Prometheus is unreachable
  #   }
  #
  #   # === PERFORMANCE MONITORING ===
  #   tel.performance_monitoring_enabled = true
  #   tel.slow_query_threshold_seconds = 1.0         # Detect slow operations
  #   tel.memory_threshold_mb = 100                   # Memory spike detection
  #   tel.event_sampling_rate = 1.0                   # 1.0 = 100%, 0.1 = 10% sampling
  #   tel.filtered_events = []                        # Events to exclude from collection
  # end

  # Dependency graph and bottleneck analysis configuration
  # These settings control how Tasker analyzes workflow dependencies,
  # identifies bottlenecks, and calculates impact scores for optimization.
  # config.dependency_graph do |graph|
  #   # Impact multipliers for bottleneck scoring calculations
  #   # These affect how different factors influence bottleneck impact scores
  #   graph.impact_multipliers = {
  #     downstream_weight: 5,      # Weight for downstream step count (higher = more impact)
  #     blocked_weight: 15,        # Weight for blocked step count (higher = more critical)
  #     path_length_weight: 10,    # Weight for critical path length
  #     completed_penalty: 15,     # Penalty for completed steps (reduce priority)
  #     blocked_penalty: 25,       # Penalty for blocked steps (increase priority)
  #     error_penalty: 30,         # Penalty for error steps (highest priority)
  #     retry_penalty: 10          # Penalty for retry steps (moderate priority)
  #   }
  #
  #   # Severity multipliers for state-based calculations
  #   # These adjust impact scores based on step states and conditions
  #   graph.severity_multipliers = {
  #     error_state: 2.0,          # Multiplier for steps in error state
  #     exhausted_retry_bonus: 0.5, # Additional multiplier for exhausted retries
  #     dependency_issue: 1.2       # Multiplier for dependency-related issues
  #   }
  #
  #   # Penalty constants for problematic step conditions
  #   # These add penalty points for specific retry and failure conditions
  #   graph.penalty_constants = {
  #     retry_instability: 3,      # Points per retry attempt (instability indicator)
  #     non_retryable: 10,         # Points for non-retryable failures
  #     exhausted_retry: 20        # Points for exhausted retry attempts
  #   }
  #
  #   # Severity thresholds for impact score classification
  #   # These determine when bottlenecks are classified as Critical/High/Medium/Low
  #   graph.severity_thresholds = {
  #     critical: 100,             # Score >= 100: Critical bottleneck
  #     high: 50,                  # Score >= 50: High priority bottleneck
  #     medium: 20                 # Score >= 20: Medium priority bottleneck
  #   }                            # Score < 20: Low priority
  #
  #   # Duration estimation constants for path analysis
  #   # These are used for calculating estimated execution times
  #   graph.duration_estimates = {
  #     base_step_seconds: 30,     # Estimated time per step (default)
  #     error_penalty_seconds: 60, # Additional time penalty for error steps
  #     retry_penalty_seconds: 30  # Additional time penalty per retry attempt
  #   }
  # end

  # Execution and performance configuration
  # These settings control concurrent step execution, memory management,
  # and timeout behavior for optimal performance and system tuning.
  # config.execution do |exec|
  #   # === CONCURRENCY SETTINGS ===
  #   # These control dynamic concurrency calculation bounds
  #   exec.min_concurrent_steps = 3           # Conservative lower bound for system stability
  #   exec.max_concurrent_steps_limit = 12    # Upper bound (should align with DB connection pool)
  #   exec.concurrency_cache_duration = 30    # Cache duration in seconds for concurrency calculations
  #
  #   # === TIMEOUT CONFIGURATION ===
  #   # These control batch execution timeouts with automatic calculation
  #   exec.batch_timeout_base_seconds = 30    # Base timeout before per-step adjustments
  #   exec.batch_timeout_per_step_seconds = 5 # Additional timeout per step in batch
  #   exec.max_batch_timeout_seconds = 120    # Absolute maximum timeout cap
  #
  #   # === ARCHITECTURAL CONSTANTS (Ruby-specific, not configurable) ===
  #   # These are set based on Ruby/Rails characteristics and should not be changed:
  #   # - future_cleanup_wait_seconds: 1 second (optimal for Concurrent::Future cleanup)
  #   # - gc_trigger_batch_size_threshold: 6 operations (Ruby memory pressure detection)
  #   # - gc_trigger_duration_threshold: 30 seconds (Ruby GC timing characteristics)
  # end

  # Backoff and retry configuration
  # These settings control retry timing, exponential backoff calculations,
  # and task reenqueue delays for optimal failure recovery.
  # config.backoff do |backoff|
  #   # Default backoff progression for retry attempts (in seconds)
  #   # Each element represents the backoff time for that attempt number.
  #   # For attempts beyond this array, exponential backoff calculation is used.
  #   backoff.default_backoff_seconds = [1, 2, 4, 8, 16, 32]
  #
  #   # Maximum backoff time to cap exponential backoff calculations
  #   # Prevents excessively long delays between retry attempts
  #   backoff.max_backoff_seconds = 300  # 5 minutes maximum
  #
  #   # Multiplier for exponential backoff calculation
  #   # Formula: backoff_time = attempt_number ^ backoff_multiplier * base_seconds
  #   backoff.backoff_multiplier = 2.0
  #
  #   # Whether to apply jitter to backoff calculations
  #   # Helps prevent "thundering herd" when many steps retry simultaneously
  #   backoff.jitter_enabled = true
  #
  #   # Maximum jitter percentage for randomization
  #   # E.g., 0.1 means Â±10% variation in backoff times
  #   backoff.jitter_max_percentage = 0.1
  #
  #   # Task reenqueue delays for different execution states
  #   # Controls how long to wait before retrying tasks in different states
  #   backoff.reenqueue_delays = {
  #     has_ready_steps: 0,              # Steps ready - immediate processing
  #     waiting_for_dependencies: 45,    # Waiting for dependencies - moderate delay
  #     processing: 10                   # Steps processing - short delay
  #   }
  #
  #   # Default reenqueue delay for unclear or unmatched states
  #   backoff.default_reenqueue_delay = 30
  #
  #   # Buffer time added to optimal backoff calculations
  #   # Ensures steps are definitely ready for retry when tasks are reenqueued
  #   backoff.buffer_seconds = 5
  # end
end
